#ifndef _LIB_DISPATCH_
#define _LIB_DISPATCH_

#if !defined(__BLOCKS__)
#error "Libdispatch requires Blocks."
#elif defined(__cplusplus)
#error "Libdispatch requires Blocks, and Blocks are not currently supported in C++"
#endif

#include <stddef.h>
#include <stdint.h>
#include <stdbool.h>

#ifdef __GNUC__
#define DISPATCH_PUBLIC_API	__attribute__((__nothrow__,__visibility__("default")))
#define DISPATCH_NONNULL1	__attribute__((__nonnull__(1)))
#define DISPATCH_NONNULL2	__attribute__((__nonnull__(2)))
#define DISPATCH_NONNULL3	__attribute__((__nonnull__(3)))
#define DISPATCH_NONNULL12	__attribute__((__nonnull__(1,2)))
#define DISPATCH_NONNULL2	__attribute__((__nonnull__(2)))
#define DISPATCH_NONNULL3	__attribute__((__nonnull__(3)))
#define DISPATCH_NONNULL_ALL	__attribute__((__nonnull__))
#define DISPATCH_PURE	__attribute__((__pure__))
#define DISPATCH_WARN_RESULT	__attribute__((__warn_unused_result__))
#define DISPATCH_MALLOC	__attribute__((__malloc__))
#else
/*! @parseOnly */
#define DISPATCH_PUBLIC_API
/*! @parseOnly */
#define DISPATCH_NONNULL1
/*! @parseOnly */
#define DISPATCH_NONNULL2
/*! @parseOnly */
#define DISPATCH_NONNULL3
/*! @parseOnly */
#define DISPATCH_NONNULL12
/*! @parseOnly */
#define DISPATCH_NONNULL_ALL
/*! @parseOnly */
#define DISPATCH_PURE
/*! @parseOnly */
#define DISPATCH_WARN_RESULT
/*! @parseOnly */
#define DISPATCH_MALLOC
#endif


/*!
 * @header
 *
 * Libdispatch is an abstract model for expressing asynchronous work.
 *
 * At its core, libdispatch provides serial FIFO work queues to which
 * units of work may be submitted.  After work is completed, a completion
 * callback is returned to the current queue at the time the work was
 * submitted.  The main thread's current queue is known as the main queue.
 * The main queue is created automatically and is the default location for
 * completion callbacks to be received.
 *
 * In order to process completion callbacks on the main queue, the main
 * thread must call into dispatch_main() or use a CFRunLoop.
 *
 * Other queues which are created by the application perform their work,
 * and receive their completion callbacks, on threads which are fully
 * managed by libdispatch.  The only guarantee is that a queue will only
 * execute one unit of work or completion callback at a time; however,
 * the specific thread on which the execution occurs may change between
 * invocations.  When multiple queues have work to be processed,
 * libdispatch is free to allocate additional worker threads to process
 * the work concurrently.  When queues are idle, these threads are
 * automatically released.
 *
 * Note on Objective-C and C++ compatibility:
 *
 * Libdispatch is a C level API.
 * Libdispatch does not catch exceptions generated by higher level languages.
 * Developers MUST catch all exceptions before a given work or completion
 * callback function returns.
 *
 * Note on POSIX threads compatibility:
 *
 * Libdispatch manages the relationship between work queues and threads.
 *
 * Developers MUST NOT delete or mututate objects that they did not create.
 * Therefore, the following APIs MUST NOT be called against threads created by
 * libdispatch.
 *
 * pthread_cancel()
 * pthread_detach()
 * pthread_join()
 * pthread_kill()
 * pthread_exit()
 *
 * Developers MAY call the following APIs if-and-only-if they restore the
 * thread back to the original state before returning to libdispatch.
 *
 * pthread_setcancelstate()
 * pthread_setcanceltype()
 * pthread_setschedparam()
 * pthread_sigmask()
 * pthread_setugid_np()
 * pthread_chdir()
 * pthread_fchdir()
 *
 * Developers MUST NOT rely on the following APIs returning predictable results
 * between invocations of libdispatch work functions and completion callbacks:
 *
 * pthread_self()
 * pthread_getschedparam()
 * pthread_get_stacksize_np()
 * pthread_get_stackaddr_np()
 * pthread_mach_thread_np()
 * pthread_from_mach_thread_np()
 *
 * The result of pthread_self() can change between invocations of work
 * functions or between the invocation of completion callbacks, but the value
 * will not change during the lifetime of any given work function or completion
 * callback. Please be cognizant of that fact when using pthread_setspecific()
 * and pthread_getspecific(). In particular, one cannot use per-thread data to
 * transmit information from the work function to the completion function. One
 * also cannot make any assumptions about "when" the destructor passed to
 * pthread_key_create() is called.  Libdispatch only promises that it will get
 * called. Libdispatch may do so between calls to work functions, or during the
 * "idle" state of a process.
 *
 * Any future or overlooked POSIX threading API that deletes or otherwise
 * modifies the life cycle of a pthread_t object will be added to these lists.
 *
 */

/*!
 * @typedef	dispatch_item_t
 *
 * @abstract
 * Dispatch items are used to track work being done asynchronously.
 * They consist of a work function, target dispatch queue, an optional
 * completion callback with an originating queue (where the completion
 * callback will be submitted), and an optional application defined context.
 *
 * @discussion
 * Dispatch items are returned if and only if completion functions are supplied,
 * and the validity of a dispatch item expires when the completion function
 * returns.
 *
 * The same dispatch item that is created by dispatch_call() will be passed
 * as an argument to the work function and completion functions.  Therefore
 * the dispatch item context provided to dispatch_call() will be available
 * to each of these functions.
 *
 * Because submitting work to a queue schedules it for later execution
 * (potentially on a different thread) it is important that any context associated
 * with the dispatch item not refer to anything on the stack of the caller to
 * dispatch_call().  It is a recommended practice that the dispatch item receive
 * ownership of the data in its context and free the data as part of its
 * completion callback (or at the end of its work function if no completion
 * callback is specified).
 *
 * Cancellation may be requested for an item via dispatch_item_cancel(), however
 * the cancellation is advisory. The work function and completion function will
 * always be invoked (in order to provide the application with well defined
 * semantics for memory management), and it is up to each to test for cancellation
 * via dispatch_item_testcancel() and return.
 */
typedef struct dispatch_item_s *dispatch_item_t;

/*!
 * @typedef	dispatch_queue_t
 *
 * @abstract
 * Dispatch queues execute work function submitted to them serially in FIFO
 * order.  A queue will only execute one work function at a time, but multiple
 * queues may each execute their work items concurrently.
 * Work is submitted to a dispatch queue via dispatch_call().
 *
 * @discussion
 * Dispatch queues are lightweight objects to which work functions may be
 * submitted.  Libdispatch automatically manages a pool of worker threads
 * to dequeue work serially from dispatch queues in FIFO order.
 *
 * Conceptually any dispatch queue may have its own thread of execution,
 * and interaction between queues is highly asynchronous.  The completion
 * callback from work submitted to a queue may be used to coordinate
 * activity between dispatch queues.
 *
 * When a queue is scheduled for deletion via dispatch_queue_delete(), it
 * will remain valid long enough to complete the currently running work
 * function, any work functions that are submitted by the current work
 * function (and so on), and any outstanding completion callbacks.
 * Once this activity has ceased, the queue's deletion callback will be
 * submitted to the queue which created it.  The queue will be disposed
 * when the deletion callback returns.
 *
 * When deletion is scheduled via dispatch_queue_delete(), an optional
 * flag may be passed which marks all current items on the queue for
 * cancellation in order to expedite the process of draining remaining
 * work from the queue.  Any further work items submitted internally
 * on the queue will be immediately marked for cancellation as well.
 *
 * Submitting work from outside a dispatch queue (i.e. not the current
 * queue) that is scheduled for deletion is undefined.
 */
typedef struct dispatch_queue_s *dispatch_queue_t;

/*!
 * @typedef	dispatch_queue_attr_t
 *
 * @abstract
 * Attribute and policy extensions.
 *
 * @discussion
 * Pass NULL for now.
 */
typedef struct dispatch_queue_attr_s *dispatch_queue_attr_t;


/*!
 * @typedef     dispatch_block_t
 *
 * @abstract
 * The prototype of work functions submitted to dispatch queues,
 * and their completion callbacks.
 *
 * @param item
 * The dispatch item that represents this work function, its
 * corresponding completion callback (if specified), and
 * application context data.
 *
 * Work functions and completion callbacks are responsible for
 * periodically testing whether the dispatch item has been
 * cancelled via dispatch_item_testcancel().  If so, the work
 * function or completion callback should free resources and
 * return.
 */
typedef void (^dispatch_block_t)(dispatch_item_t item);

/* @typedef	dispatch_queue_deletion_t
 *
 * @abstract
 * The prototype of the dispatch queue deletion callback.
 *
 * @param queue
 * The dispatch queue that has been scheduled for deletion.
 * By the time this deletion callback has been invoked, the
 * queue will have completed all work items submitted to it,
 * and will have received all outstanding completion callbacks
 * for work it requested.  Receipt of this callback is an
 * opportunity for the application to release any resources
 * associated with the queue's context.  The queue itself will
 * be freed when the deletion callback returns, and its
 * reference will subsequently become invalid.
 */
typedef void (^dispatch_queue_deletion_block_t)(dispatch_queue_t queue);

/*!
 * @function	dispatch_call
 *
 * @abstract
 * Schedules a work function for asynchronous execution on
 * a dispatch queue.  An optional completion callback will
 * be delivered to the current queue when the work function
 * has completed.  The dispatch_call() function always
 * returns immediately after the work has been submitted,
 * and never waits for the work to be performed.
 *
 * @discussion
 * The dispatch_call() function is the fundamental mechanism
 * for submitting work to a dispatch queue.  It allocates
 * a dispatch item which contains a reference to the work
 * function, optional completion callback, current queue,
 * and any application provided context.
 *
 * The dispatch item is valid until the completion callback
 * returns, and may be used to request cancellation of the
 * work.
 *
 * This dispatch item will be provided to the work function
 * and optional completion callback.  However, the dispatch
 * item will only be returned to the caller if a completion
 * callback has been provided (otherwise the caller would
 * have no way to determine the validity period of the
 * dispatch item).
 *
 * The completion callback will be submitted to the current
 * queue at the time the call to dispatch_call() is made.
 * If a completion callback is specified and there is no
 * current queue, the call to dispatch_call() will fail.
 *
 * Calls to dispatch_call() are non-blocking and the function
 * will return immediately after the item has been submitted
 * to the destination queue.
 *
 * @param	queue
 * The dispatch queue to which the work function is submitted.
 * If this queue has been scheduled for deletion (and is not
 * the current queue) the results are undefined.
 *
 * @param	work
 * The work function to be performed on the target dispatch
 * queue.  This work will be performed asynchronously: either
 * after the current work function if submitted to the current
 * dispatch queue, or potentially concurrently if submitted to
 * another dispatch queue.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the work function Block, and will perform a Block_release()
 * after the work function has returned.
 *
 * @param	completion
 * The completion callback function to be submitted on the
 * current queue after the completion of the work function.
 * This parameter is optional and may be NULL.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the completion function Block, and will perform a Block_release()
 * after the completion function has returned.
 *
 * @param	context
 * The context of the dispatch item, available to both the
 * work function and the completion callback function via
 * the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @param	item
 * If this parameter is not NULL and a completion callback function
 * has been provided, then a reference to the newly created dispatch
 * item will be returned.  This reference is valid until the completion
 * callback function has returned.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */

DISPATCH_PUBLIC_API DISPATCH_NONNULL1
bool
dispatch_call(dispatch_queue_t queue,
	dispatch_block_t work,
	dispatch_block_t completion,
	void* context,
	dispatch_item_t *item);

/*!
 * @function	dispatch_call_wait
 *
 * @abstract
 * A blocking variant of dispatch_call() taking no completion
 * callback parameter.  This function will block until the work
 * function has finished executing on the target queue.
 *
 * @discussion
 * See dispatch_call() for more details.
 *
 * Important: using dispatch_call_wait() is subject to the same
 * same multi-party dead-lock problems that may result from the
 * use of a mutex.
 *
 * As a result, use of this blocking variant is discouraged.
 * Instead it is recommended to provide a completion callback
 * to dispatch_call().  Use of completion callbacks will
 * typically result in more efficient resource utilization.
 *
 * @param	queue
 * The dispatch queue to which the work function is submitted.
 * If this queue has been scheduled for deletion (and is not
 * the current queue) the results are undefined.
 *
 * @param	work
 * The work function to be performed on the target dispatch
 * queue.  This work will be performed asynchronously: either
 * after the current work function if submitted to the current
 * dispatch queue, or potentially concurrently if submitted to
 * another dispatch queue.
 *
 * @param	context
 * The context of the dispatch item, available to the work
 * function via the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL1
bool
dispatch_call_wait(dispatch_queue_t queue,
		dispatch_block_t work,
		void *context);

/*!
 * @function	dispatch_apply
 *
 * @abstract
 * Schedules a work function for asynchronous (and potentially
 * concurrent) execution a given number of times.
 *
 * @discussion
 * Schedules a work function for asynchronous (and potentially
 * concurrent) execution a given number of times.  The function
 * must be re-entrant safe as it may be invoked concurrently with
 * itself (and may be invoked concurrently with the caller).
 *
 * The work function invocations will share the current queue
 * as the caller of dispatch_apply().  Any completion callbacks
 * for dispatch items created inside the work function will be
 * returned to the current queue.  Similarly any dispatch event
 * sources created in the work function will be registered with
 * the current queue.
 *
 * This function allows a dispatch item to "fan out" an operation
 * for concurrent execution on multiple processors.
 *
 * All invocations of the work function will be passed the same
 * dispatch item reference.  Each invocation of the work function
 * may determine its interation number via dispatch_item_get_index().
 *
 * @param	work
 * The work function to be performed the specified number of
 * times.  This work will be performed asynchronously and may
 * be executed concurrently with both the current dispatch item,
 * and with other invocation of the work function.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the work function Block, and will perform a Block_release()
 * after all invocations of the work function have returned.
 *
 * @param	iterations
 * The number of iterations to perform on the work function.
 *
 * @param	completion
 * The completion callback function to be submitted on the
 * current queue after the completion of all invocations
 * of the work function.
 * This parameter is optional and may be NULL.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the completion function Block, and will perform a Block_release()
 * after the completion function has returned.
 *
 * @param	context
 * The context of the dispatch item, available to all invocations
 * of the work function and the completion callback function via
 * the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @param	item
 * If this parameter is not NULL and a completion callback function
 * has been provided, then a reference to the newly created dispatch
 * item will be returned.  This reference is valid until the completion
 * callback function has returned.
 *
 * This reference is shared for all invocations of the work function
 * and a single call to dispatch_item_cancel() will be visible to all
 * outstanding invocations.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */
DISPATCH_PUBLIC_API
bool
dispatch_apply(dispatch_block_t work,
			  size_t iterations,
			  dispatch_block_t completion,
			  void *context,
			  dispatch_item_t *item);

/*!
 * @function	dispatch_apply_wait
 *
 * @abstract
 * A blocking variant of dispatch_apply() taking no completion
 * callback parameter.  This function will block until the work
 * function has finished executing.
 *
 * @discussion
 * See dispatch_apply() for more details.
 *
 * @param	work
 * The work function to be performed the specified number of
 * times.  Each invocation of the work function may be
 * executed concurrently with each other.
 *
 * @param	iterations
 * The number of iterations to perform on the work function.
 *
 * @param	context
 * The context of the dispatch item, available to all invocations
 * of the work function and the completion callback function via
 * the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */
DISPATCH_PUBLIC_API
bool
dispatch_apply_wait(dispatch_block_t work,
					size_t iterations,
					void *context);

/*!
 * @function	dispatch_subtasks
 *
 * @abstract
 * Schedules an array of work functions for asynchronous
 * (and potentially concurrent) execution.
 *
 * @discussion
 * Schedules an array of work functions for asynchronous
 * (and potentially concurrent) execution.
 * The functions may be invoked concurrently with the caller
 * and with each other.
 *
 * Each of the work functions will share the current queue
 * as the caller of dispatch_apply().  Any completion callbacks
 * for dispatch items created inside each work function will be
 * returned to the current queue.  Similarly any dispatch event
 * sources created in each work function will be registered with
 * the current queue.
 *
 * This function allows a dispatch item to "fan out" multiple
 * subtasks for concurrent execution on multiple processors.
 *
 * All invocations of the work functions will be passed the same
 * dispatch item reference.  Each work function may determine its
 * position in the submitted array of work functions via a call
 * to dispatch_item_get_index().
 *
 * @param	work
 * The work functions to be performed as subtasks.
 * This work will be performed asynchronously and may
 * be executed concurrently with both the current dispatch item,
 * and with the other work functions in the array.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * each work function Block, and will perform a Block_release()
 * after each invocation of the work function has returned.
 *
 * @param	count
 * The number of elements of the work function array.
 *
 * @param	completion
 * The completion callback function to be submitted on the
 * current queue after the completion of all invocations
 * of the work functions.
 * This parameter is optional and may be NULL.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the completion function Block, and will perform a Block_release()
 * after the completion function has returned.
 *
 * @param	context
 * The context of the dispatch item, available to all invocations
 * of the work functions and the completion callback function via
 * the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @param	item
 * If this parameter is not NULL and a completion callback function
 * has been provided, then a reference to the newly created dispatch
 * item will be returned.  This reference is valid until the completion
 * callback function has returned.
 *
 * This reference is shared for all invocations of the work functions
 * and a single call to dispatch_item_cancel() will be visible to all
 * outstanding invocations.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */
DISPATCH_PUBLIC_API
bool
dispatch_subtasks(dispatch_block_t *work,
				size_t count,
				dispatch_block_t completion,
				void *context,
				dispatch_item_t* item);

/*!
 * @function	dispatch_subtasks_wait
 *
 * @abstract
 * A blocking variant of dispatch_subtasks() taking no completion
 * callback parameter.  This function will block until the work
 * functions have finished executing.
 *
 * @discussion
 * See dispatch_subtasks() for more details.
 *
 * @param	work
 * The work functions to be performed as subtasks.
 * These work functions may be executed concurrently with
 * each other.
 *
 * @param	count
 * The number of elements of the work function array.
 *
 * @param	context
 * The context of the dispatch item, available to all invocations
 * of the work functions and the completion callback function via
 * the dispatch_item_get_context() accessor.
 * This parameter is optional and may be NULL.
 *
 * @result
 * True if the work is successfully scheduled, otherwise false.
 */
DISPATCH_PUBLIC_API
bool
dispatch_subtasks_wait(dispatch_block_t *work,
				size_t count,
				void *context);

/*!
 * @function	dispatch_queue_get_current
 *
 * @abstract
 * Returns the queue to which the current work item was submitted,
 * or if called from the main thread, returns the main queue.
 * 
 * @discussion
 * When called from within a dispatch_block_t callout, this function
 * returns the queue to which the current work function was submitted,
 * or to which the current completion callback was returned.
 * If called from the main thread, the main queue is returned.
 * The NULL pointer is returned if called from any other context.
 *
 * @result
 * Returns the current queue.
 */
DISPATCH_PUBLIC_API DISPATCH_PURE DISPATCH_WARN_RESULT
dispatch_queue_t
dispatch_queue_get_current(void);

/*!
 * @function	dispatch_queue_get_main
 *
 * @result
 * Returns the main queue (associated with the main thread).
 * This queue is created automatically on behalf of main()
 * and conceptually is created before main() is called.
 *
 * Work functions submitted to this queue will not be executed
 * until a call to dispatch_main() is made, or unless a CFRunLoop
 * is used on the main thread.
 */
DISPATCH_PUBLIC_API DISPATCH_PURE DISPATCH_WARN_RESULT
dispatch_queue_t
dispatch_queue_get_main(void);

/*!
 * @function	dispatch_queue_new
 *
 * @abstract
 * Creates a new dispatch queue to which work functions may be
 * submitted.
 *
 * @discussion
 * Dispatch queues execute work functions serially in FIFO order.
 *
 * A string label and application defined context may be associated
 * with newly created queues.
 *
 * The dispatch queue refernce is valid until the queue has been
 * deleted.  When a queue is scheduled for deletion, and all
 * activity on the queue has ceased, the queue's deletion callback
 * will be submitted to the queue that was current when the new
 * queue was created.
 *
 * Receipt of the deletion function provides an application the
 * opportunity to release any resources associted with the queue's
 * context.
 *
 * After the deletion callback returns, all references to the
 * dispatch queue become invalid.
 *
 * @param	label
 * A string label to attach to the queue.
 * The string is NOT copied and must remain valid for the lifetime
 * of the queue.
 * This parameter is optional and may be NULL.
 *
 * @param	flags
 * Reserved for future use.  Pass 0 for now.
 *
 * @param	deletion
 * The deletion callback function that will be submitted to the current
 * queue (at the time of the call to dispatch_queue_new()) when
 * the queue has been scheduled for deletion and finished all remaining
 * work functions and completion callbacks.
 *
 * Note on Blocks: libdispatch will perform a Block_copy() on
 * the deletion function Block, and will perform a Block_release()
 * after the deletion function has returned.
 *
 * @param	context
 * An application defined context to be associated with the queue.
 * This context may be retrieved via dispatch_queue_get_context().
 * This parameter is optional and may be NULL.
 *
 * @param	attr
 * Future attribute and policy extensions. Pass NULL for now.
 *
 * @result
 * The newly created dispatch queue.
 */
DISPATCH_PUBLIC_API DISPATCH_MALLOC DISPATCH_WARN_RESULT
dispatch_queue_t
dispatch_queue_new(const char *label,
		uint64_t flags,
		dispatch_queue_deletion_block_t deletion,
		void *context,
		dispatch_queue_attr_t attr);

/*!
 * @enum
 * @const	DISPATCH_QUEUE_CANCEL
 * Bulk cancel the remaining work functions on a dispatch
 * queue when the queue is scheduled for deletion.
 */
enum {
	DISPATCH_QUEUE_CANCEL = 2,
};

/*!
 * @function	dispatch_queue_delete
 *
 * @param	queue
 * The queue to delete. If this parameter is NULL the behavior is
 * undefined.
 *
 * @param	flags
 * Pass DISPATCH_QUEUE_CANCEL to cancel all remaining work.
 * Otherwise, pass zero.
 *
 * @abstract
 * Schedules a queue for deletion. No new work is allowed to be added.
 *
 * @discussion
 * The queue will not be deleted until three milestones have occured. First,
 * the queue of work functions is drained. Second, all outstanding completion
 * callbacks have returned. Third, the deletion callback supplied at the time
 * of queue creation has returned.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL
void
dispatch_queue_delete(dispatch_queue_t queue, uint64_t flags);

/*!
 * @function	dispatch_queue_get_label
 *
 * @abstract
 * Returns the label of the queue that was specified at queue creation time.
 *
 * @param	queue
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The label of the queue. The result may be NULL.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL DISPATCH_PURE DISPATCH_WARN_RESULT
const char *
dispatch_queue_get_label(dispatch_queue_t queue);

/*!
 * @function	dispatch_queue_get_context
 *
 * @abstract
 * Returns the application defined context of the queue.
 *
 * @param	queue
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The context of the queue. The result may be NULL.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL DISPATCH_PURE DISPATCH_WARN_RESULT
void *
dispatch_queue_get_context(dispatch_queue_t queue);

/*!
 * @function	dispatch_queue_set_context
 *
 * @abstract
 * Set the context of the queue.
 *
 * @param	queue
 * The result of passing NULL in this parameter is undefined.
 *
 * @param	context
 * The new application defined context for the queue. This may be NULL.
 *
 * @result
 * The previous context of the queue. The result may be NULL.
 *
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL1
void *
dispatch_queue_set_context(dispatch_queue_t queue, void *context);

/*!
 * @function	dispatch_queue_suspend
 *
 * @param	queue
 * The queue. Passing NULL is undefined.
 *
 * @result
 * Returns the total number of suspensions (after increment).
 *
 * @abstract
 * Schedules the suspension of a queue.
 *
 * @discussion
 * The current item will run to completion.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL
size_t
dispatch_queue_suspend(dispatch_queue_t queue);

/*!
 * @function	dispatch_queue_resume
 *
 * @param	queue
 * The queue. Passing NULL is undefined.
 *
 * @result
 * Returns the total number of suspensions (after decrement).
 *
 * @abstract
 * Schedules the resumption of a queue if the suspension count drops to
 * zero.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL
size_t
dispatch_queue_resume(dispatch_queue_t queue);

/*!
 * @function	dispatch_queue_get_suspend_count
 *
 * @param	queue
 * The queue to inspect. Passing NULL is undefined.
 *
 * @result
 * Returns the total number of suspensions.
 */

DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL DISPATCH_WARN_RESULT
size_t
dispatch_queue_get_suspend_count(dispatch_queue_t queue);

/*!
 * @function	dispatch_item_get_index
 *
 * @abstract
 * Returns the index of the current work function associated with
 * a multi-part dispatch item created by dispatch_apply() or
 * dispatch_subtasks().
 *
 * @discussion
 * When called from within a work function supplied to dispatch_apply()
 * or dispatch_apply_wait(), the index gives the current iteration number
 * of the applier function (from 0 to 'iterations'-1).
 *
 * When called from within a work function supplied to dispatch_subtasks()
 * or dispatch_subtasks_wait(), the index gives the array index of the
 * currently executing work function in the array of work functions
 * provided.
 *
 * Calling dispatch_item_get_index() from any other context is undefined.
 *
 * @param	item
 * The result of passing NULL in this parameter is undefined.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL DISPATCH_WARN_RESULT
size_t
dispatch_item_get_index(dispatch_item_t item);

/*!
 * @function	dispatch_item_get_context
 *
 * @abstract
 * Returns the application defined context associated with a
 * dispatch item.
 *
 * @param	item
 * The result of passing NULL in this parameter is undefined.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL DISPATCH_WARN_RESULT
void*
dispatch_item_get_context(dispatch_item_t item);

/*!
 * @function	dispatch_item_cancel
 *
 * @abstract
 * Marks the dispatch item for cancellation.
 * 
 * @discussion
 * In order to provide well-defined semantics for application
 * memory management, cancellation of dispatch work items is
 * advisory.
 *
 * A dispatch item's work function and completion callback
 * function (if provided) will always be invoked, regardless o
 * the dispatch item's cancellation status.
 *
 * It is the responsibility of dispatch item work functions and
 * completion callback functions to periodically test the
 * cancellation status of the dispatch item via
 * dispatch_item_test_cancel().  If the dispatch item has been
 * cancelled, the function should release resources and return.
 *
 * @param	item
 * The dispatch item to cancel.
 * The result of passing NULL in this parameter is undefined.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL_ALL
void
dispatch_item_cancel(dispatch_item_t item);

/*!
 * @function	dispatch_item_testcancel
 *
 * @abstract
 * Tests the current cancellation status of a dispatch item.
 * Dispatch items are marked for cancellation via a call to
 * dispatch_item_cancel().
 *
 * @param	item
 * The dispatch item to test cancellation status.
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * Returns true when the dispatch item has been marked for
 * cancellation, otherwise false.
 */
DISPATCH_PUBLIC_API DISPATCH_WARN_RESULT
bool
dispatch_item_testcancel(dispatch_item_t item);

/*!
 * @function	dispatch_item_defer_reply
 *
 * @abstract
 * Defers the completion callback from being scheduled after the
 * curently executing work function returns until a later time
 * as specifed by a call to dispatch_item_send_reply().
 *
 * @discussion
 * This function defers the completion callback of the current
 * dispatch item until a later time as specified by a call to
 * dispatch_item_send_reply().  Ordinarily, completion callbacks
 * are scheduled as soon as the work function returns.  However,
 * deferring the completion callback allows additional
 * asynchronous processing to be performed, and dependencies
 * between completion callbacks to be implemented.
 *
 * The dispatch_item_defer_reply() function may only be called
 * from within the context of a currently executing work function.
 * The result of calling this function with a dispatch item that
 * is not currently executing its work function is undefined.
 * 
 * Important note: if dispatch_item_send_reply() is never called,
 * then the dispatch item is effectively leaked.  Furthermore,
 * if the dispatch item was originally created via a blocking
 * mechanism such as dispatch_call_wait(), the caller of that
 * function will never unblock.
 *
 * @param	item
 * The currently executing work function's item.
 * The result of passing NULL in this parameter is undefined.
 */
DISPATCH_PUBLIC_API
void
dispatch_item_defer_reply(dispatch_item_t item);

/*!
 * @function	dispatch_item_send_reply
 *
 * @abstract
 * Delivers the completion callback of a dispatch item whose
 * completion callback was previously deferred via a call to
 * dispatch_item_defer_reply().
 *
 * @discussion
 * This function enables the delivery of a dispatch item's
 * completion callback that had been previously deferred via
 * a call to dispatch_item_defer_reply().
 * 
 * Calling this function with a dispatch item whose result
 * has not been previously deferred is undefined.
 * Calling this function more than once with the same dispatch
 * item is also undefined.
 *
 * @param	item
 * A dispatch item whose completion callback has been previously
 * deferred via a call to dispatch_item_defer_reply().
 * The result of passing NULL in this parameter is undefined.
 */
DISPATCH_PUBLIC_API DISPATCH_NONNULL1
void
dispatch_item_send_reply(dispatch_item_t item);

/*!
 * @function	dispatch_main
 *
 * @discussion
 * Applications must calls this function in order to process work function
 * and completion callbacks submitted to the main queue. 
 *
 * @abstract
 * This function "parks" the main thread in libdispatch and provides
 * an opportunity for work functions and completion callbacks submitted
 * to the main queue to be performed.
 *
 * Note on CoreFoundation, Foundation, and AppKit integration:
 * Applications that call NSApplicationMain() or CFRunLoopRun() do not
 * need to call dispatch_main().
 */
DISPATCH_PUBLIC_API
void
dispatch_main(void);

#endif
